#Read csv file, remove Loan_ID column
dataset = read.csv("data/dataset.csv") %>% select(-Loan_ID)
#Display first few rows of table
head(dataset)
count <- table(dataset$Loan_Status)
barplot(height = count, xlab = "LoanStatus")
#Oversampling
dataset <- dataset %>% rbind(dataset[dataset['Loan_Status'] == 'N',])
#Display metadata
str(dataset)
#Convert from int to factor
dataset$Loan_Amount_Term <- as.factor(dataset$Loan_Amount_Term)
#Store names of continuous variables
cont_var <- c('ApplicantIncome', 'CoapplicantIncome', 'LoanAmount')
#Display no of nas in all columns
lapply(dataset, function(x) sum(is.na(x)))
#Display frequencies of all possible values
table(dataset$Loan_Amount_Term)
table(dataset$Credit_History)
#Remove na
dataset$LoanAmount <- replace(dataset$LoanAmount, is.na(dataset$LoanAmount), values = mean(dataset$LoanAmount, na.rm = TRUE))
dataset$Loan_Amount_Term[is.na(dataset$Loan_Amount_Term)] <- 360
dataset$Credit_History[is.na(dataset$Credit_History)] <- 0
#Preprocess data
categorical <- dataset %>% select(-cont_var)
continuous <- dataset %>% select(cont_var)
preprocessor <- preProcess(x = continuous)
new_dataset <- preprocessor %>%
predict(continuous) %>% cbind(categorical)
#new_dataset <- dataset
#Plot correlation matrix
cor(new_dataset[cont_var])
#Plot histograms of continuous variables
dataset %>% select(cont_var, -LoanAmount) %>% gather() %>% ggplot(aes(value)) +
facet_wrap(~ key) +
geom_histogram(bins = 50)
dataset['LoanAmount'] %>% gather() %>% ggplot(aes(x = value)) + geom_histogram(bins = 30) + ggtitle("LoanAmount")
#Plot boxplots of continuous variables
dataset %>% select(cont_var, -LoanAmount) %>% boxplot()
boxplot(dataset['LoanAmount'], names = c("LoanAmount"))
#Plot barplots of categorical variables
counts <- table(dataset$Loan_Status, dataset$Gender)
barplot(counts, legend = rownames(counts), main = "Gender")
counts <- table(dataset$Loan_Status, dataset$Married)
barplot(counts, legend = rownames(counts), main = "Married")
counts <- table(dataset$Loan_Status, dataset$Dependents)
barplot(counts, legend = rownames(counts), main = "Dependents")
counts <- table(dataset$Loan_Status, dataset$Education)
barplot(counts, legend = rownames(counts), main = "Education")
counts <- table(dataset$Loan_Status, dataset$Self_Employed)
barplot(counts, legend = rownames(counts), main = "Self_Employed")
counts <- table(dataset$Loan_Status, dataset$Loan_Amount_Term)
barplot(counts, legend = rownames(counts), main = "Loan_Amount_Term")
counts <- table(dataset$Loan_Status, dataset$Credit_History)
barplot(counts, legend = rownames(counts), main = "Credit_History")
counts <- table(dataset$Loan_Status, dataset$Property_Area)
barplot(counts, legend = rownames(counts), main = "Property_Area")
#Split dataset into training and testing datasets
train_indices <- createDataPartition(y = new_dataset$Loan_Status, p = 0.8, list = FALSE)
training <- new_dataset[train_indices,]
test <- new_dataset[-train_indices,]
#Initiate training controls
control <- trainControl(method = "cv", number = 10, p = 0.8, search = "grid")
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "nn", trControl = control, metric = "Accuracy")
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "adaboost", trControl = control, metric = "Accuracy")
md
#Test
x_test <- test[,1:ncol(test) - 1]
y_test <- test[,ncol(test)]
y_pred <- predict(md, x_test)
confusionMatrix(data = y_pred, reference = y_test, positive = "Y")
#Save model for future prediction
saveRDS(object = md, file = "model.rds")
#Import libraries
library(mlr, warn.conflicts = FALSE)
library(caret, warn.conflicts = FALSE)
library(tidyr)
library(purrr, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(magrittr, warn.conflicts = FALSE)
library(ggplot2)
source("scripts/Preprocess.R")
source("scripts/Predict.R")
#Read csv file, remove Loan_ID column
dataset = read.csv("data/dataset.csv") %>% select(-Loan_ID)
#Display first few rows of table
head(dataset)
count <- table(dataset$Loan_Status)
barplot(height = count, xlab = "LoanStatus")
#Oversampling
dataset <- dataset %>% rbind(dataset[dataset['Loan_Status'] == 'N',])
#Display metadata
str(dataset)
#Convert from int to factor
dataset$Loan_Amount_Term <- as.factor(dataset$Loan_Amount_Term)
#Store names of continuous variables
cont_var <- c('ApplicantIncome', 'CoapplicantIncome', 'LoanAmount')
#Display no of nas in all columns
lapply(dataset, function(x) sum(is.na(x)))
#Display frequencies of all possible values
table(dataset$Loan_Amount_Term)
table(dataset$Credit_History)
#Remove na
dataset$LoanAmount <- replace(dataset$LoanAmount, is.na(dataset$LoanAmount), values = mean(dataset$LoanAmount, na.rm = TRUE))
dataset$Loan_Amount_Term[is.na(dataset$Loan_Amount_Term)] <- 360
dataset$Credit_History[is.na(dataset$Credit_History)] <- 0
#Preprocess data
categorical <- dataset %>% select(-cont_var)
continuous <- dataset %>% select(cont_var)
preprocessor <- preProcess(x = continuous)
new_dataset <- preprocessor %>%
predict(continuous) %>% cbind(categorical)
#new_dataset <- dataset
#Plot correlation matrix
cor(new_dataset[cont_var])
#Plot histograms of continuous variables
dataset %>% select(cont_var, -LoanAmount) %>% gather() %>% ggplot(aes(value)) +
facet_wrap(~ key) +
geom_histogram(bins = 50)
dataset['LoanAmount'] %>% gather() %>% ggplot(aes(x = value)) + geom_histogram(bins = 30) + ggtitle("LoanAmount")
#Plot boxplots of continuous variables
dataset %>% select(cont_var, -LoanAmount) %>% boxplot()
boxplot(dataset['LoanAmount'], names = c("LoanAmount"))
#Plot boxplots of continuous variables
dataset %>% select(cont_var, -LoanAmount) %>% boxplot()
boxplot(dataset['LoanAmount'], names = c("LoanAmount"))
#Plot barplots of categorical variables
counts <- table(dataset$Loan_Status, dataset$Gender)
barplot(counts, legend = rownames(counts), main = "Gender")
counts <- table(dataset$Loan_Status, dataset$Married)
barplot(counts, legend = rownames(counts), main = "Married")
counts <- table(dataset$Loan_Status, dataset$Dependents)
barplot(counts, legend = rownames(counts), main = "Dependents")
counts <- table(dataset$Loan_Status, dataset$Education)
barplot(counts, legend = rownames(counts), main = "Education")
counts <- table(dataset$Loan_Status, dataset$Self_Employed)
barplot(counts, legend = rownames(counts), main = "Self_Employed")
counts <- table(dataset$Loan_Status, dataset$Loan_Amount_Term)
barplot(counts, legend = rownames(counts), main = "Loan_Amount_Term")
counts <- table(dataset$Loan_Status, dataset$Credit_History)
barplot(counts, legend = rownames(counts), main = "Credit_History")
counts <- table(dataset$Loan_Status, dataset$Property_Area)
barplot(counts, legend = rownames(counts), main = "Property_Area")
#Split dataset into training and testing datasets
train_indices <- createDataPartition(y = new_dataset$Loan_Status, p = 0.8, list = FALSE)
training <- new_dataset[train_indices,]
test <- new_dataset[-train_indices,]
#Initiate training controls
control <- trainControl(method = "cv", number = 10, p = 0.8, search = "grid")
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "adaboost", trControl = control, metric = "Accuracy")
md
#Test
x_test <- test[,1:ncol(test) - 1]
y_test <- test[,ncol(test)]
y_pred <- predict(md, x_test)
confusionMatrix(data = y_pred, reference = y_test, positive = "Y")
#Save model for future prediction
saveRDS(object = md, file = "model.rds")
colnames(dataset[,1:ncol(dataset) - 1]) %>% saveRDS(file = "feature_list.rds")
saveRDS(object = dataset[0:0, 1:ncol(dataset) - 1], file = "model/frame_format.rds")
colnames(dataset)
#Prediction example
dummy_frame <- readRDS("frame_format.rds")
dummy_frame[nrow(dummy_frame) + 1,] = dataset[8, 1:ncol(dataset) - 1]
print(dataset[8, ncol(dataset)])
ans <- predict_data(dummy_frame, preprocessor)
ans
install.packages("mice")
#Import libraries
library(mlr, warn.conflicts = FALSE)
library(caret, warn.conflicts = FALSE)
library(tidyr)
library(purrr, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(magrittr, warn.conflicts = FALSE)
library(ggplot2)
library(mice)
source("scripts/Preprocess.R")
source("scripts/Predict.R")
#Import libraries
library(mlr, warn.conflicts = FALSE)
library(caret, warn.conflicts = FALSE)
library(tidyr)
library(purrr, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(magrittr, warn.conflicts = FALSE)
library(ggplot2)
library(mice, warn.conflicts = FALSE)
source("scripts/Preprocess.R")
source("scripts/Predict.R")
imputed_dataset <- mice(data = dataset)
imputed_dataset <- mice(data = dataset)
imputed_dataset
imputed_dataset
imputed_dataset <- complete(mice(data = dataset))
imputed_dataset
imputed_dataset
imputed_dataset %>% lapply(function(val) sum(is.na(val)))
#Import libraries
library(mlr, warn.conflicts = FALSE)
library(caret, warn.conflicts = FALSE)
library(tidyr)
library(purrr, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(magrittr, warn.conflicts = FALSE)
library(ggplot2)
library(mice, warn.conflicts = FALSE)
source("scripts/Preprocess.R")
source("scripts/Predict.R")
#Read csv file, remove Loan_ID column
dataset = read.csv("data/dataset.csv") %>% select(-Loan_ID)
#Display first few rows of table
head(dataset)
count <- table(dataset$Loan_Status)
barplot(height = count, xlab = "LoanStatus")
#Oversampling
dataset <- dataset %>% rbind(dataset[dataset['Loan_Status'] == 'N',])
#Display metadata
str(dataset)
#Convert from int to factor
dataset$Loan_Amount_Term <- as.factor(dataset$Loan_Amount_Term)
#Store names of continuous variables
cont_var <- c('ApplicantIncome', 'CoapplicantIncome', 'LoanAmount')
#Display no of nas in all columns
lapply(dataset, function(x) sum(is.na(x)))
#Display frequencies of all possible values
table(dataset$Loan_Amount_Term)
table(dataset$Credit_History)
#Remove na
dataset$LoanAmount <- replace(dataset$LoanAmount, is.na(dataset$LoanAmount), values = mean(dataset$LoanAmount, na.rm = TRUE))
dataset$Loan_Amount_Term[is.na(dataset$Loan_Amount_Term)] <- 360
dataset$Credit_History[is.na(dataset$Credit_History)] <- 0
imputed_dataset <- complete(mice(data = dataset))
imputed_dataset
imputed_dataset %>% lapply(function(val) sum(is.na(val)))
#Preprocess data
categorical <- imputed_dataset %>% select(-cont_var)
continuous <- imputed_dataset %>% select(cont_var)
preprocessor <- preProcess(x = continuous)
new_dataset <- preprocessor %>%
predict(continuous) %>% cbind(categorical)
#Plot correlation matrix
cor(new_dataset[cont_var])
#Plot histograms of continuous variables
dataset %>% select(cont_var, -LoanAmount) %>% gather() %>% ggplot(aes(value)) +
facet_wrap(~ key) +
geom_histogram(bins = 50)
dataset['LoanAmount'] %>% gather() %>% ggplot(aes(x = value)) + geom_histogram(bins = 30) + ggtitle("LoanAmount")
#Plot boxplots of continuous variables
dataset %>% select(cont_var, -LoanAmount) %>% boxplot()
boxplot(dataset['LoanAmount'], names = c("LoanAmount"))
#Plot barplots of categorical variables
counts <- table(dataset$Loan_Status, dataset$Gender)
barplot(counts, legend = rownames(counts), main = "Gender")
counts <- table(dataset$Loan_Status, dataset$Married)
barplot(counts, legend = rownames(counts), main = "Married")
counts <- table(dataset$Loan_Status, dataset$Dependents)
barplot(counts, legend = rownames(counts), main = "Dependents")
counts <- table(dataset$Loan_Status, dataset$Education)
barplot(counts, legend = rownames(counts), main = "Education")
counts <- table(dataset$Loan_Status, dataset$Self_Employed)
barplot(counts, legend = rownames(counts), main = "Self_Employed")
counts <- table(dataset$Loan_Status, dataset$Loan_Amount_Term)
barplot(counts, legend = rownames(counts), main = "Loan_Amount_Term")
counts <- table(dataset$Loan_Status, dataset$Credit_History)
barplot(counts, legend = rownames(counts), main = "Credit_History")
counts <- table(dataset$Loan_Status, dataset$Property_Area)
barplot(counts, legend = rownames(counts), main = "Property_Area")
#Split dataset into training and testing datasets
train_indices <- createDataPartition(y = new_dataset$Loan_Status, p = 0.8, list = FALSE)
training <- new_dataset[train_indices,]
test <- new_dataset[-train_indices,]
#Initiate training controls
control <- trainControl(method = "cv", number = 10, p = 0.8, search = "grid")
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "adaboost", trControl = control, metric = "Accuracy")
md
#Test
x_test <- test[,1:ncol(test) - 1]
y_test <- test[,ncol(test)]
y_pred <- predict(md, x_test)
confusionMatrix(data = y_pred, reference = y_test, positive = "Y")
#Save model for future prediction
saveRDS(object = md, file = "model.rds")
colnames(dataset[,1:ncol(dataset) - 1]) %>% saveRDS(file = "feature_list.rds")
saveRDS(object = dataset[0:0, 1:ncol(dataset) - 1], file = "model/frame_format.rds")
colnames(dataset)
#Prediction example
dummy_frame <- readRDS("frame_format.rds")
dummy_frame[nrow(dummy_frame) + 1,] = dataset[8, 1:ncol(dataset) - 1]
print(dataset[8, ncol(dataset)])
ans <- predict_data(dummy_frame, preprocessor)
ans
source('C:/Users/Piyush/Desktop/Loan Prediction/scripts/Predict.R', echo=TRUE)
#Import libraries
library(mlr, warn.conflicts = FALSE)
library(caret, warn.conflicts = FALSE)
library(tidyr)
library(purrr, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(magrittr, warn.conflicts = FALSE)
library(ggplot2)
library(mice, warn.conflicts = FALSE)
source("scripts/Preprocess.R")
#Split dataset into training and testing datasets
train_indices <- createDataPartition(y = new_dataset$Loan_Status, p = 0.8, list = FALSE)
training <- new_dataset[train_indices,]
test <- new_dataset[-train_indices,]
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "xgbDART", trControl = control, metric = "Accuracy")
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "naive_bayes", trControl = control, metric = "Accuracy")
md
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "mlpKerasDropoutCost", trControl = control, metric = "Accuracy")
install.packages("tensorflow")
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "mlpKerasDropoutCost", trControl = control, metric = "Accuracy")
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "awnb", trControl = control, metric = "Accuracy")
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "mxnetAdam", trControl = control, metric = "Accuracy")
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "AdaBag", trControl = control, metric = "Accuracy")
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "AdaBag", trControl = control, metric = "Accuracy")
md
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "AdaBoost.M1", trControl = control, metric = "Accuracy")
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "adaboost", trControl = control, metric = "Accuracy")
#Import libraries
library(mlr, warn.conflicts = FALSE)
library(caret, warn.conflicts = FALSE)
library(tidyr)
library(purrr, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(magrittr, warn.conflicts = FALSE)
library(ggplot2)
library(mice, warn.conflicts = FALSE)
source("scripts/Preprocess.R")
#Split dataset into training and testing datasets
train_indices <- createDataPartition(y = new_dataset$Loan_Status, p = 0.8, list = FALSE)
#Import libraries
library(mlr, warn.conflicts = FALSE)
library(caret, warn.conflicts = FALSE)
library(tidyr)
library(purrr, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(magrittr, warn.conflicts = FALSE)
library(ggplot2)
library(mice, warn.conflicts = FALSE)
source("scripts/Preprocess.R")
#Read csv file, remove Loan_ID column
dataset = read.csv("data/dataset.csv") %>% select(-Loan_ID)
#Import libraries
library(mlr, warn.conflicts = FALSE)
library(caret, warn.conflicts = FALSE)
library(tidyr)
library(purrr, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(magrittr, warn.conflicts = FALSE)
library(ggplot2)
library(mice, warn.conflicts = FALSE)
source("scripts/Preprocess.R")
#Import libraries
library(mlr, warn.conflicts = FALSE)
library(caret, warn.conflicts = FALSE)
library(tidyr)
library(purrr, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(magrittr, warn.conflicts = FALSE)
library(ggplot2)
library(mice, warn.conflicts = FALSE)
source("scripts/Preprocess.R")
#Import libraries
library(mlr, warn.conflicts = FALSE)
library(caret, warn.conflicts = FALSE)
library(tidyr)
library(purrr, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(magrittr, warn.conflicts = FALSE)
library(ggplot2)
library(mice, warn.conflicts = FALSE)
source("scripts/Predict.R")
#Import libraries
library(mlr, warn.conflicts = FALSE)
library(caret, warn.conflicts = FALSE)
library(tidyr)
library(purrr, warn.conflicts = FALSE)
library(dplyr, warn.conflicts = FALSE)
library(magrittr, warn.conflicts = FALSE)
library(ggplot2)
library(mice, warn.conflicts = FALSE)
source("scripts/Predict.R")
#Read csv file, remove Loan_ID column
dataset = read.csv("data/dataset.csv") %>% select(-Loan_ID)
#Display first few rows of table
head(dataset)
count <- table(dataset$Loan_Status)
barplot(height = count, xlab = "LoanStatus")
#Oversampling
dataset <- dataset %>% rbind(dataset[dataset['Loan_Status'] == 'N',])
#Display metadata
str(dataset)
#Convert from int to factor
dataset$Loan_Amount_Term <- as.factor(dataset$Loan_Amount_Term)
#Store names of continuous variables
cont_var <- c('ApplicantIncome', 'CoapplicantIncome', 'LoanAmount')
#Display no of nas in all columns
lapply(dataset, function(x) sum(is.na(x)))
#Display frequencies of all possible values
table(dataset$Loan_Amount_Term)
table(dataset$Credit_History)
#Remove na
dataset$LoanAmount <- replace(dataset$LoanAmount, is.na(dataset$LoanAmount), values = mean(dataset$LoanAmount, na.rm = TRUE))
dataset$Loan_Amount_Term[is.na(dataset$Loan_Amount_Term)] <- 360
dataset$Credit_History[is.na(dataset$Credit_History)] <- 0
imputed_dataset <- complete(mice(data = dataset))
imputed_dataset
imputed_dataset %>% lapply(function(val) sum(is.na(val)))
#Preprocess data
categorical <- imputed_dataset %>% select(-cont_var)
continuous <- imputed_dataset %>% select(cont_var)
preprocessor <- preProcess(x = continuous)
new_dataset <- preprocessor %>%
predict(continuous) %>% cbind(categorical)
#Plot correlation matrix
cor(new_dataset[cont_var])
#Plot histograms of continuous variables
dataset %>% select(cont_var, -LoanAmount) %>% gather() %>% ggplot(aes(value)) +
facet_wrap(~ key) +
geom_histogram(bins = 50)
dataset['LoanAmount'] %>% gather() %>% ggplot(aes(x = value)) + geom_histogram(bins = 30) + ggtitle("LoanAmount")
#Plot boxplots of continuous variables
dataset %>% select(cont_var, -LoanAmount) %>% boxplot()
boxplot(dataset['LoanAmount'], names = c("LoanAmount"))
#Plot barplots of categorical variables
counts <- table(dataset$Loan_Status, dataset$Gender)
barplot(counts, legend = rownames(counts), main = "Gender")
counts <- table(dataset$Loan_Status, dataset$Married)
barplot(counts, legend = rownames(counts), main = "Married")
counts <- table(dataset$Loan_Status, dataset$Dependents)
barplot(counts, legend = rownames(counts), main = "Dependents")
counts <- table(dataset$Loan_Status, dataset$Education)
barplot(counts, legend = rownames(counts), main = "Education")
counts <- table(dataset$Loan_Status, dataset$Self_Employed)
barplot(counts, legend = rownames(counts), main = "Self_Employed")
counts <- table(dataset$Loan_Status, dataset$Loan_Amount_Term)
barplot(counts, legend = rownames(counts), main = "Loan_Amount_Term")
counts <- table(dataset$Loan_Status, dataset$Credit_History)
barplot(counts, legend = rownames(counts), main = "Credit_History")
counts <- table(dataset$Loan_Status, dataset$Property_Area)
barplot(counts, legend = rownames(counts), main = "Property_Area")
#Split dataset into training and testing datasets
train_indices <- createDataPartition(y = new_dataset$Loan_Status, p = 0.8, list = FALSE)
training <- new_dataset[train_indices,]
test <- new_dataset[-train_indices,]
#Initiate training controls
control <- trainControl(method = "cv", number = 10, p = 0.8, search = "grid")
#Train
x_train <- training[,1:ncol(training) - 1]
y_train <- training[,ncol(training)]
md <- caret::train(x = x_train, y = y_train, method = "adaboost", trControl = control, metric = "Accuracy")
md
#Test
x_test <- test[,1:ncol(test) - 1]
y_test <- test[,ncol(test)]
y_pred <- predict(md, x_test)
confusionMatrix(data = y_pred, reference = y_test, positive = "Y")
#Save model for future prediction
saveRDS(object = md, file = "model/model.rds")
colnames(dataset[,1:ncol(dataset) - 1]) %>% saveRDS(file = "feature_list.rds")
saveRDS(object = dataset[0:0, 1:ncol(dataset) - 1], file = "model/frame_format.rds")
colnames(dataset)
#Prediction example
dummy_frame <- readRDS("frame_format.rds")
dummy_frame[nrow(dummy_frame) + 1,] = dataset[8, 1:ncol(dataset) - 1]
print(dataset[8, ncol(dataset)])
ans <- predict_data(dummy_frame, preprocessor)
ans
